# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BT-nxnDwMZkB6tdiNCzL4DM61qvGNfsb
"""

# Installation
!pip install scanpy
!pip install anndata
!pip3 install igraph
!pip install celltypist
!pip install decoupler
!pip install fa2-modified

# Import libraries (core single cell tools)
import scanpy as sc
import anndata as ad

# Upload the data
!wget https://github.com/josoga2/sc/raw/refs/heads/main/bone_marrow.h5ad
BM_adata = sc.read_h5ad('bone_marrow.h5ad')
print (BM_adata)

# The dimensions of our dataset
BM_adata.shape

# The first 5 rows describing the genes in our dataset
BM_adata.var.head()

# The first 5 rows describing the cells (ID) in our dataset
BM_adata.obs.head()

# Both gene and cell datasets in a proper dataframe format
BM_adata.to_df()

# A useful step for older datasets
BM_adata.var_names_make_unique()
BM_adata.obs_names_make_unique()

# Search for possible contamination from dying cells, ribosomal transcripts or haemoglobin.
BM_adata.var['MT'] = BM_adata.var['feature_name'].str.startswith("MT-")
BM_adata.var['RIBO'] = BM_adata.var['feature_name'].str.startswith("RPS", "RPL")
BM_adata.var['HB'] = BM_adata.var['feature_name'].str.startswith("^HB[^(P)]")

# See the QC data for MT, RIBO and HB.

mt_genes = BM_adata.var[BM_adata.var['MT']]
mt_genes

ribo_genes = BM_adata.var[BM_adata.var['RIBO']]
ribo_genes

hb_genes = BM_adata.var[BM_adata.var['HB']]
hb_genes

# Calculate the QC metrics
sc.pp.calculate_qc_metrics(
    BM_adata, qc_vars=["MT", 'RIBO', 'HB'], inplace=True, log1p=True
)

sc.pl.violin(
    BM_adata,
    ["n_genes_by_counts"],
    jitter=0.4,
    multi_panel=False,
)

# Note that it is also included in the headers of obs
BM_adata.obs.head()

# And your gene list
BM_adata.var.head()

# Doublet detection
sc.pp.scrublet(BM_adata)

# NORMALIZATION

# Save a copy of the data
BM_adata.layers["counts"] = BM_adata.X.copy()

# Normalizing to median total counts
sc.pp.normalize_total(BM_adata)
# Logarithmize the data
sc.pp.log1p(BM_adata)

#Feature selection
#selecting the top 1000 most variable genes
sc.pp.highly_variable_genes(BM_adata, n_top_genes=1000)

sc.pl.highly_variable_genes(BM_adata )
#left is normalized
#right is not

# PCA

sc.tl.pca(BM_adata)

sc.pl.pca_variance_ratio(BM_adata, n_pcs=10, log=False)

sc.pp.neighbors(BM_adata)

sc.tl.umap(BM_adata)

# Using the igraph implementation and a fixed number of iterations can be significantly faster, especially for larger datasets
sc.tl.leiden(BM_adata, flavor="igraph", n_iterations=2)

sc.pl.umap(
    BM_adata,
    color=["leiden"],
    size=8,
)

#Further reclustering

sc.tl.leiden(BM_adata, flavor="igraph", n_iterations=2, key_added="leiden_res0_02", resolution=0.02)
sc.tl.leiden(BM_adata, flavor="igraph", n_iterations=2, key_added="leiden_res0_5", resolution=0.5)
sc.tl.leiden(BM_adata, flavor="igraph", n_iterations=2, key_added="leiden_res2", resolution=2)

sc.pl.umap(
    BM_adata,
    color=["leiden_res0_02"],
    # increase horizontal space between panels
    wspace=0.5,
    size=15,
    ncols = 1
)

sc.pl.umap(
    BM_adata,
    color=["leiden_res0_5"],
    # increase horizontal space between panels
    wspace=0.5,
    size=15,
    ncols = 1,
    legend_loc="on data"
)

sc.pl.umap(
    BM_adata,
    color=["leiden_res2"],
    # increase horizontal space between panels
    wspace=0.5,
    size=15,
    ncols = 1,
    legend_loc="on data"
)

# This downloads the table of genes directly from ensemble
!wget wget -O result.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "CSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hsapiens_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "external_gene_name" /></Dataset></Query>'

import pandas as pd

ensembl_var = pd.read_csv('/content/result.txt', header = None)

ensembl_var.columns = ['ensembl_gene_id', 'gene_name']

ensembl_var.head(3)

import decoupler as dc

# Query Omnipath and get PanglaoDB
markers = dc.op.resource(name="PanglaoDB", organism="human")

# Keep canonical cell type markers alone
markers = markers[markers["canonical_marker"]]

# Remove duplicated entries
markers = markers[~markers.duplicated(["cell_type", "genesymbol"])]

#Format because dc only accepts cell_type and genesymbol

markers = markers.rename(columns={"cell_type": "source", "genesymbol": "target"})
markers = markers[["source", "target"]]

markers.head()

#correct target to ensemble
markers = markers.merge(ensembl_var, left_on="target", right_on="gene_name", how="left")
markers = markers.drop(columns=["target"])
# Remove duplicated entries
markers = markers[~markers.duplicated(["source", "ensembl_gene_id"])]

#Format because dc only accepts cell_type and genesymbol
markers = markers.rename(columns={"source": "source", "ensembl_gene_id": "target"})

markers = markers[["source", "target"]]
markers = markers.dropna()

markers.head()

#load the gene expression matrix into dc
dc.mt.ulm(data=BM_adata,
          net=markers,
          tmin = 3)

#retrieve the score for each cell type
score = dc.pp.get_obsm(BM_adata, key="score_ulm")
score

#preview the data
BM_adata.obsm["score_ulm"].head()

BM_adata.obsm["score_ulm"].columns

sc.pl.umap(score, color=["leiden"], cmap="RdBu_r")

import seaborn as sns

sc.pl.violin(score, keys=["T cells"], groupby="leiden", rotation=90)

# Now let's know what each of the 7 clusters mean

#rank genes
BM_adata_rank = dc.tl.rankby_group(score, groupby="leiden", reference="rest", method="t-test_overestim_var")
BM_adata_rank = BM_adata_rank[BM_adata_rank["stat"] > 0]
BM_adata_rank.head()

cluster_annotations = BM_adata_rank[BM_adata_rank["stat"] > 0].groupby("group").head(1).set_index("group")["name"].to_dict()

cluster_annotations

BM_adata.obs['cell_type'] = BM_adata.obs['leiden'].map(cluster_annotations)